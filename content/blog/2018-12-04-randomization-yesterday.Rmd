---
title: "Get me a random assignment YESTERDAY"
date: "2018-12-04"
author: "Declare Design Team"
output:
  html_document:
    highlight: tango
    theme: cerulean
    code_folding: show
bibliography: bib/blog.bib  
---

```{r setup, include=FALSE}
library(DeclareDesign)
library(knitr)
library(kableExtra)
library(blockTools)
library(tidyverse)
# library(writexl)
theme_set(theme_bw())

here_you_go <- fabricate(school = add_level(N = 20),
                         class  = add_level(N = 4, treatment = block_ra(blocks = school)))

```

You're partnering with an education nonprofit and you are planning on running a randomized control trial in 80 classrooms spread across 20 community schools. The request is in: please send us a spreadsheet with random assignments. The assignment's gotta be blocked by school, it's gotta be reproducible, and it's gotta be tonight.  The good news is that you can do all this in a couple of lines of code. We show how using some DeclareDesign tools and then walk through handling of more complex cases.

# You can do it!

We'll show first how you do it and then talk through some of the principles, wrinkles, and checks you might do. Here's the code:

```{r, warning = FALSE, message = FALSE}
library(DeclareDesign)

set.seed(20181204)

here_you_go <- fabricate(school = add_level(N = 20),
                         class  = add_level(N = 4, treatment = block_ra(blocks = school)))
```

The spreadsheet looks like this:

```{r, echo=FALSE}
here_you_go %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  scroll_box(width = "75%", height = "200px")
```

<br>

It has 20 schools with 4 classes in each and in each school exactly 2 classes are randomly assigned to treatment. The class variable provides a unique identifier for the experimental units.

The basic work here is done in a single line of code using `fabricate` from the `fabricatr` package and `block_ra` from the `randomizr` package. The `fabricatr` package helped us make a multilevel dataset (using `add_level`) and the `randomizr` package lets us specify what we want to use as blocks for a blocked random assignment.

You can then save this as a spreadsheet and send off:

```{r, eval = FALSE}
write.csv(here_you_go, file = "our_assignment_final_revised_final_version_3_latest.csv")
```

We're done. 

# Some principles and a better workflow

We got the job done. How well did the approach do in terms of satisfying various  randomization desiderata?

1. We want  random assignment to be *transparent* in the sense that the process by which units were assigned to treatment conditions is fully understandable to interested parties. The code here provides much of the needed transparency. One point of slippage perhaps here is that the there is no specification for how the units here map into the actual units in the field. There should be no ambiguity as to which classroom we are talking about when we talk about classroom 5 in school 2. If this mapping can be determined later then the randomization can come undone.

2. We want the random assignment to be *reproducible* in the sense that a person using the same software could generate the same random assignment. This is typically assured by setting a random number seed (`set.seed(20181204)`). If you give the computer a "seed" before randomizing you will get the same "random" result every time. Setting seeds produces a small risk to transparency since in principle one could select a seed to get a result you like. One approach used here is to use a rule for seed setting -- such as setting the seed as the date of the randomization. Another is to publicly post a single seed that you or your lab will use for all projects. 

3. We want to be able to verify properties of the random assignment *procedure*, not just of a particular assignment. For that, we need to be able to generate many thousands of possible random assignments. It helps immensely if the random assignment procedure is itself a function that can be called repeatedly, rather than a script or a point-and-click workflow. We have not done that here so will walk through that below. 

Rather than writing code that produces an assignment and dataframe directly it can be useful to write down a *procedure* for generating data and assignment. `DeclareDesign` functions are good for this since these are mostly *functions that make functions*.

```{r}
make_data  <- declare_population(school = add_level(N = 20),
                                 class  = add_level(N = 4))
assignment <- declare_assignment(blocks = class, prob = .5)
```

With these functions (`make_data()` and `assignment()` are functions!) written up, you have both the data structure and the assignment strategy declared. There are many ways now to run these one after another to generate a dataset with assignments. Some examples:

```{r}
our_assignment <- assignment(make_data())     # base R approach 

our_assignment <- make_data() %>% assignment  # dplyr approach 
```


The base R approach and the `dplyr` approach both run the first function and then apply the second function to the result. 

We advocate a design declaration approach that first concatenates the  two steps into a design and then draws data using the design.

```{r}
design         <- make_data + assignment
our_assignment <- draw_data(design)           # DeclareDesign approach
```

```{r, echo=FALSE}
our_assignment %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  scroll_box(width = "75%", height = "200px")
```

<br>

A nice feature of the last approach is that not only can you conduct an actual random assignment from the design but you *also* obtain the probability that each unit is in the condition that it is in. This probability happens to be constant in this example, but it doesn't need to be. If probabilities vary by unit, a standard approach is to weight each unit by the inverse of the probability of being in the condition that it is in. 

We will use this last approach going forward as we look at more bells and whistles.


# Four bells and whistles

## Incorporate known data into a dataframe before randomization

In general the world is not quite as neat as in the example above. Say in fact our data came in like this  (of course it would be easier if you were sent a nice dataset but you cannot always count on that):

> Just got the numbers: School 1 has 6 classes, school 2 has 8, schools 4 and 8 have 3 classes, schools 5 and 9 have 5, school 6 has 2, school 10 has 7. Remember we need this yesterday.

We want to incorporate this information in the data fabrication step. The `add_level` functionality in the `fabricate` function is key here for respecting the multilevel nature of the dataset.

```{r}
make_data <- declare_population(school = add_level(N = 10),
                                class  = add_level(N = c(6, 8, 4, 3, 5, 2, 4, 3, 5, 7)))
```


This new function would generate a data set that reflects the number of classes in each school.

## Make better blocks from richer data 

Say that you had even richer data about the sampling frame. Then you could use this to do even better assignments. Say this is what you get from your partner:

> We just got information on the class sizes. Here it is: School 1: 20, 25, 23, 30, 12, 15; School 2: 40, 42, 53, 67, 35, 22, 18, 18; School 3: 34, 37, 28, 30; School 4: 18, 24, 20; School 5: 10, 24, 13, 26, 18; School 6: 20, 25; School 7: 28, 34, 19, 24; School 8: 32, 25, 31; School 9: 23, 20, 33, 22, 35; School 10: 20, 31, 34, 35, 18, 23, 22

We want to incorporate this information in the data fabrication step. 

```{r}
make_data <- declare_population(
    school = add_level(N = 10),
    class = add_level(N = c(6, 8, 4, 3, 5, 2, 4, 3, 5, 7),
                size = c(
                  20, 25, 23, 30, 12, 15,         # students in each classroom of school 1
                  40, 42, 53, 67, 35, 22, 18, 18, # students in each classroom of school 2
                  34, 37, 28, 30,                 # etc...
                  18, 24, 20,
                  10, 24, 13, 26, 18,
                  20, 25,
                  28, 34, 19, 24,
                  32, 25, 31,
                  23, 20, 33, 22, 35,
                  20, 31, 34, 35, 18, 23, 22
                )))
```

This new data on class sizes might be very useful.

If the NGO wants to examine individual level outcomes but is using a classroom-level intervention, then this design is using "clustered" random assignment (students clustered into classrooms). As noted in @imai2009essential, however, if clusters are of uneven sizes, standard estimation approaches can be biased, even though it's a randomized experiment. They propose blocking on cluster size in order to address this problem. We'll use [`blockTools`](https://cran.r-project.org/web/packages/blockTools/index.html) (by Ryan T. Moore and Keith Schnakenberg) to block on both school and classroom size within schools.

The `block` function within `blockTools` forms blocks as a function of `size` by pairing similarly-sized classrooms (blocks of size 2 is the default for the `block` function, though this can be changed). By telling the function that classes are grouped within schools, we can ensure that `blockTools` will pair classrooms within the same school. We turn this functionality into a design step like this:

```{r}
# A step to generate blocks
block_function <- function(data) {
    out <- block(data, id.vars = "class", groups = "school", block.vars = "size")
    mutate(data, block_id = createBlockIDs(out, data, id.var = "class"))}

make_blocks <- declare_step(handler =  block_function)
```

Let's make a design that includes this step and now uses `block_id` instead of `class` for blocking:

```{r}
design <- make_data + make_blocks + declare_assignment(blocks = block_id)
```

When we draw data we now get the block variables and the assignment probabilities included. One out of two units is assigned to each block of two and singleton blocks are assigned independently with 0.5 probability to treatment.

```{r}
our_df <- draw_data(design)
```

```{r, echo=FALSE}
our_df %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  scroll_box(width = "75%", height = "200px")
```

<br>

The graph below shows that indeed, the blocking formed pairs of classrooms within each school that are similar to one another and correctly left some classrooms in a block by themselves when there was an odd number of classrooms in a school.

```{r}
our_df %>%
  ggplot(aes(size, block_id, color = as.factor(Z))) +
  geom_point() +
  facet_wrap(~school, scales = "free_y", ncol = 5)
```

## Replicate yourself

If you set up your assignments as functions like this then it is easy to implement the assignment multiple times:

```{r, eval = FALSE}
many_assignments <- replicate(1000, draw_data(design))
```

It's useful to preserve a collection of assignments like this. One advantage is that it lets you see directly what the *real* assignment probabilities are---not just the intended assignment probabilities. This is especially useful in complex randomizations where different units might get assigned to treatment with quite different probabilities depending on their characteristics (for instance a procedure that rejects assignment profiles because of concerns with imbalance). Calculating the actual probabilities lets you figure out if you have set things up correctly and in some cases can even be useful for correcting things at the analysis stage if you have not!^[Some tools in the `randomizr` package make it even easier to obtain matrices of permutations and to learn about properties of your assignments. Using the `randomizr` package you can declare a randomization like this  `ra_declaration <- declare_ra(blocks = class)` and then get a print out of features of the assignments using `summary(ra_declaration)` and a whole matrix of assignments like this `perm_mat <- obtain_permutation_matrix(ra_declaration)`] In addition the collection of assignments stored in `many_assignment` are exactly the assignments you should use for some randomization inference tests.  

## Save the output to an excel spreadsheet

Your partners mightn't love csv spreadsheets. But you can easily save to other formats.

Many people love Microsoft Excel. Using the [`writexl`](https://cran.r-project.org/web/packages/writexl/index.html) package (by Jeroen Ooms) will make them happy:

```{r, eval = FALSE}
library(writexl)

set_seed(20181204)

our_df <- draw_data(design)

write_xlsx(our_df, path = "students_with_random_assignment.xlsx")
```



# Summary

1. Sometimes you need to *make* data from bits of information. `fabricatr` can help with that.
2. Sometimes you need to make blocks from multiple pieces of information. `blockTools` can help with that.
3. Sometimes you need to conduct a random assignment (and make sure it's reproducible). The functions in `randomizr` can help with that.
4. Sometimes you need to share data with people who use Excel. `writexl` can help with that!
5. Think of all this together as a  part of a design declaration and you get a guarantee that all the bits *do* fit together in a transparent and replicable way, plus you are half way to a full declaration. 

# References.
